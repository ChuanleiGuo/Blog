<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"chuanleiguo.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"hide","padding":18,"offset":12,"onmobile":true},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="分类问题线性回归的内容讨论了如何使用线性模型进行回归学习，并对未来样本做出预测。但是，如果我们要解决分类问题的话，应该怎么做？可不可以利用线性模型来完成分类任务？ 利用线性回归解决分类问题对于二分类问题，一种简单的想法是，我们对一个简单的线性函数设置一个阈值（threshold）。我们使用一个线性函数对样本进行预测，当预测值大于 threshold 时，我们将样本的类别判断为真（或 1 ）；当预测">
<meta property="og:type" content="article">
<meta property="og:title" content="【机器学习课程笔记】| Logistic Regression">
<meta property="og:url" content="http://chuanleiguo.com/2017/01/01/Logistic-Regression/index.html">
<meta property="og:site_name" content="Chuan&#39;s Cabin">
<meta property="og:description" content="分类问题线性回归的内容讨论了如何使用线性模型进行回归学习，并对未来样本做出预测。但是，如果我们要解决分类问题的话，应该怎么做？可不可以利用线性模型来完成分类任务？ 利用线性回归解决分类问题对于二分类问题，一种简单的想法是，我们对一个简单的线性函数设置一个阈值（threshold）。我们使用一个线性函数对样本进行预测，当预测值大于 threshold 时，我们将样本的类别判断为真（或 1 ）；当预测">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://chuanleiguo.com/images/2017-1-1/Group%202.png">
<meta property="og:image" content="http://chuanleiguo.com/images/2017-1-1/Group1.png">
<meta property="og:image" content="http://chuanleiguo.com/images/2017-1-1/Screen%20Shot%202016-12-31%20at%2020.52.42.png">
<meta property="og:image" content="http://chuanleiguo.com/images/2017-1-1/Screen%20Shot%202017-01-01%20at%2019.33.08.png">
<meta property="og:image" content="http://chuanleiguo.com/images/2017-1-1/Screen%20Shot%202017-01-01%20at%2019.33.37.png">
<meta property="article:published_time" content="2017-01-01T01:26:23.000Z">
<meta property="article:modified_time" content="2020-12-08T10:55:57.900Z">
<meta property="article:author" content="Chuanlei Guo">
<meta property="article:tag" content="MOOC">
<meta property="article:tag" content="Machine Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://chuanleiguo.com/images/2017-1-1/Group%202.png">

<link rel="canonical" href="http://chuanleiguo.com/2017/01/01/Logistic-Regression/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>【机器学习课程笔记】| Logistic Regression | Chuan's Cabin</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container {
  overflow: auto hidden;
}

mjx-container + br {
  display: none;
}
</style></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Chuan's Cabin</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Code & Live with Love</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-programming-language">

    <a href="/categories/programming-language" rel="section"><i class="fa fa-rocket fa-fw"></i>编程语言</a>

  </li>
        <li class="menu-item menu-item-sourcecode">

    <a href="/categories/sourcecode" rel="section"><i class="fa fa-code fa-fw"></i>源码分析</a>

  </li>
        <li class="menu-item menu-item-computer-science">

    <a href="/categories/computer-science" rel="section"><i class="fa fa-cogs fa-fw"></i>计算机科学</a>

  </li>
        <li class="menu-item menu-item-mooc">

    <a href="/categories/mooc" rel="section"><i class="fa fa-graduation-cap fa-fw"></i>MOOC</a>

  </li>
        <li class="menu-item menu-item-booknotes">

    <a href="/categories/booknotes" rel="section"><i class="fa fa-book fa-fw"></i>读书笔记</a>

  </li>
        <li class="menu-item menu-item-diary">

    <a href="/categories/diary" rel="section"><i class="fa fa-keyboard fa-fw"></i>日志</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://chuanleiguo.com/2017/01/01/Logistic-Regression/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chuanlei Guo">
      <meta itemprop="description" content="正因为未知，人与人之间的羁绊才愈发迷人">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chuan's Cabin">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          【机器学习课程笔记】| Logistic Regression
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2017-01-01 09:26:23" itemprop="dateCreated datePublished" datetime="2017-01-01T09:26:23+08:00">2017-01-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-12-08 18:55:57" itemprop="dateModified" datetime="2020-12-08T18:55:57+08:00">2020-12-08</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mooc/" itemprop="url" rel="index"><span itemprop="name">MOOC</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2017/01/01/Logistic-Regression/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/01/01/Logistic-Regression/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="分类问题"><a href="#分类问题" class="headerlink" title="分类问题"></a>分类问题</h1><p>线性回归的内容讨论了如何使用线性模型进行回归学习，并对未来样本做出预测。但是，如果我们要解决分类问题的话，应该怎么做？可不可以利用线性模型来完成分类任务？</p>
<h2 id="利用线性回归解决分类问题"><a href="#利用线性回归解决分类问题" class="headerlink" title="利用线性回归解决分类问题"></a>利用线性回归解决分类问题</h2><p>对于二分类问题，一种简单的想法是，我们对一个简单的线性函数设置一个阈值（threshold）。我们使用一个线性函数对样本进行预测，当预测值大于 threshold 时，我们将样本的类别判断为真（或 1 ）；当预测值小于 threshold 时，我们将样本判断为假（或 0 ）。</p>
<p>我们需要将预测值转化为 0/1 值，所以我们可以定义模型为：</p>
<p>$$<br> y =<br>    \begin{cases}<br>        1 &amp; \quad h_{\theta} \geq 0.5 \<br>        0 &amp; \quad h_{\theta} &lt; 0.5    \<br>    \end{cases}<br>$$</p>
<p>但问题在于这个函数是不可靠的，例如，当我们有6个样本时，我们根据现有样本做线性回归，可以得到如下的拟合曲线：</p>
<p><img src="/images/2017-1-1/Group%202.png" alt="Group 2"></p>
<p>如图，下面的三个样本被判定为假，上面的三个样本被判定为真。但是当样本数量增加时， 我们的拟合曲线可能会造成判断错误，出现较大的误差。</p>
<p><img src="/images/2017-1-1/Group1.png" alt="Group1"></p>
<p>我们根据新的9个样本进行线性回归，到得到的新的回归曲线。在 $x = 1.25$ 处的样本，它的值大于0.5，应该被判断为真；但是新的回归曲线在该点的函数值小于0.5，所以该样本会被错误地判断为假。</p>
<p>所以，单纯地使用线性回归方法实现二分类是不合适的。</p>
<h2 id="Sigmoid-函数"><a href="#Sigmoid-函数" class="headerlink" title="Sigmoid 函数"></a>Sigmoid 函数</h2><p>我们可以使用 Sigmoid 函数，它有非常良好的数学性质，例如：单调可微，在 $0 \dots 1$ 之间变化等。Sigmoid 函数的表达式为： $$ y = \frac{1}{1 + \mathrm{e}^{-\mathrm{z}}} $$<br>它的函数图形为：</p>
<p><img src="/images/2017-1-1/Screen%20Shot%202016-12-31%20at%2020.52.42.png" alt="Screen Shot 2016-12-31 at 20.52.42"></p>
<p>在有了 Sigmoid 方程后，我们可以令 $ z = \theta^{T}x $。也可以得到：<br>$$ y = \frac{1}{1 + e^{-\theta^{T}x}} $$<br>即：<br>$$ ln\frac{y}{1-y} = \theta^{T}x $$<br>我们可以将 $y$ 看做样本 $x$ 为正例的可能性，将 $1 - y$ 看做样本 $x$ 为反例的可能性。也就是说，我们是在用线性回归模型的预测结果去逼近真实标记的对数几率。所以，这个模型被称为“对数几率回归”（Logistic Regression）。</p>
<p>在这个模型中，我们是直接对分类可能心进行建模，而且无需实现假设分布，这样就可以避免假设分布不准确所带来的问题；它不是仅仅预测出“类别”，而是可以得到近似的概率预测；最后，Sigmoid 函数是一种任意阶可导的凸函数，有很多数值计算方法可以用来求取最优解。</p>
<h1 id="Cost-Function"><a href="#Cost-Function" class="headerlink" title="Cost Function"></a>Cost Function</h1><p>对于线性回归模型，我们定义的代价函数（Cost Function）是所有模型误差的平方和。理论上讲，我们可以对逻辑回归模型沿用这个定义，但是问题在于，当我们将 $ h_{\theta} = \frac{1}{1 + e^{-\theta^{T}x}} $ 带入到代价函数中时，我们得到的代价函数将是非凸函数（non-convex function）。这意味着我们的代价函数有许多局部最小值，这将影响梯度下降算法寻找全局最小值。</p>
<p>所以，我们重新定义逻辑回归的代价函数为:</p>
<p>$$J(\theta) = \frac{1}{m}\sum_{1}^{m}Cost(h_{\theta}(x^{(i)}, y^{(i)}))$$</p>
<p>其中：</p>
<p>$$ Cost(h_{\theta}, y) =<br>\begin{cases}<br>        -log(h_{\theta}(x))     &amp; \quad y = 1 \<br>        -log(1 - h_{\theta}(x)) &amp; \quad y = 0 \<br>\end{cases}<br>$$</p>
<p>$h_{\theta}(x)$与$Cost(h_{\theta}(x), y)$之间的关系如下图所示：</p>
<p><img src="/images/2017-1-1/Screen%20Shot%202017-01-01%20at%2019.33.08.png" alt="Screen Shot 2017-01-01 at 19.33.08"><br><img src="/images/2017-1-1/Screen%20Shot%202017-01-01%20at%2019.33.37.png" alt="Screen Shot 2017-01-01 at 19.33.37"></p>
<p>这样构建的 $Cost(h_{\theta},y)$ 的特点是：当实际的$y=1$且$h_{\theta}$也为1时误差为0，当$y = 1$但$h_{\theta}$不为1时，误差随着$h_{\theta}$的变小而变大；当实际的$y = 0$且$h_{\theta}$也为0时，代价为0，当$y=0$但$h_{\theta}$不为0时，误差随着$h_{\theta}$的变大而变大。</p>
<p>这样，我们可以得到简化后的 $Cost(h_{\theta}(x), y)$:</p>
<p>$$ Cost(h_{\theta}(x),y) = -ylog(h_{\theta}(x))-(1-y)log(1-h_{\theta}(x))$$</p>
<p>带入代价方程我们可以得到：</p>
<p>$$<br>J(\theta) = -\frac{1}{m}[\sum_{i=1}^{m}y^{(i)}logh_{\theta}(x^{(i)})+(1-y^{(i)})og(1-h_{\theta}(x))]<br>$$</p>
<p>有了这样一个代价函数后，我们就可以使用梯度下降的算法来求得能使代价最小的参数了。</p>
<h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>查了梯度下降算法外，我们还可以使用一些常常被用来计算最小代价的算法，这些算法更加复杂和优越，而且不需要人工干预学习率，且比梯度下降算法更加快速。比如：Conjugate Gradient, BFGS, L-BFGS等。我们在实现求解 Logistic Regression 的参数的时候，可以跟根据自己所使用的语言或平台来利用这些函数，从而实现快速、高效的参数学习。</p>
<h1 id="多分类问题"><a href="#多分类问题" class="headerlink" title="多分类问题"></a>多分类问题</h1><p>在多分类问题中，我们要训练的样本属于多个类，我们无法使用二元变量对这些类别进行区分。例如，我们要预测一个学生的学习情况，可分为：差、良和优秀。一种解决多分类问题的方法被称为 “One-vs-All” 算法。</p>
<h2 id="One-vs-All"><a href="#One-vs-All" class="headerlink" title="One-vs-All"></a>One-vs-All</h2><p>使用 “One-vs-All” 方法，我们将多分类问题，转化为二分类问题。为了实现这样的转变，我们将其中的一个类标记为正类（$y = 1$），其他所有类别标记为负类，这个模型被记作$h_{\theta}^{(1)}(x)$。接着类似地我们将另外一个类选择为正类（$y=2$），其他类别标记为负类，这个模型被记作$h_{\theta}^{(2)}(x)$。以此类推。</p>
<p>我们可以得到分类器模型：$h_{\theta}^{(i)}=p(y=i|x;\theta) \quad i \in [1 \dots k]$。</p>
<p>在预测中，我们要运行每一个分类器，并对每一个输入变量，都选择最高可能性的输出变量。</p>
<h2 id="过度拟合问题（Overfitting）"><a href="#过度拟合问题（Overfitting）" class="headerlink" title="过度拟合问题（Overfitting）"></a>过度拟合问题（Overfitting）</h2><p>如果我们的模型中有数目过多的属性，那么我们通过学习所得到的属性可能会非常好得适应训练样本（代价函数的值几乎为0），但是可能无法推广到新的样本中。</p>
<p>如果我们遇到了过拟合问题，一般有两种方法：</p>
<ol>
<li>减少属性数目<br> 可以是手工选择保留那些属性，也可以运行某些属性选择算法。</li>
<li>归一化（Regularization）<br> 保留所有的属性，但是减少某些属性的重要性（Magnitude）。当我们有很多对预测结果有略微作用的属性时，归一化的效果非常好。</li>
</ol>
<h2 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h2><h3 id="Regularization-Cost-Funtion"><a href="#Regularization-Cost-Funtion" class="headerlink" title="Regularization - Cost Funtion"></a>Regularization - Cost Funtion</h3><p>例如在某问题中，我们的预测模型为：</p>
<p>$$ h_{\theta}(x)=\theta_{0}+\theta_{1}x_{1}+\theta_{2}x_{2}^{2}+\theta_{3}x_{3}^{3}+\theta_{4}x_{4}^{4} $$</p>
<p>我们决定减少$\theta_3$和$\theta_4$的作用，要做得就是修改代价函数，为$\theta_3$和$\theta_4$设置一点惩罚。这样的话，我们在尝试最小化代价函数的同时，也需要将这个惩罚纳入考虑中，修改后的代价函数可以是：<br>$$<br>min_{\theta}\frac{1}{2m}\sum_{i=1}^{m}((h_{\theta}(x^{(i)})-y^{(i)})+1000\theta_{3}^{2}+10000\theta_{4}^{2})<br>$$</p>
<p>通过这样的代价函数，我们选择得出的$\theta_{3}$和$\theta_{4}$对预测结果的影响要比之前小得多。</p>
<p>假如我们有非常多的特征，我们并不知道其中哪些特征我们要惩罚，我们将对所有的特征进行惩罚，并且让代价函数最优化的软件来选择这些惩罚的程度。这样的结果是得到了一个较为简单的能防止过拟合问题的假设：</p>
<p>$$<br>J(\theta)=\frac{1}{2m}\big[\sum_{i=1}^{m}((h_{\theta}(x^{(i)})-y^{(i)})^{2})+\lambda\sum_{j=1}^{n}{\theta}_{j}^{2} \big]<br>$$</p>
<p>注意：我们不对$\theta_{0}$进行惩罚。</p>
<p>但是如果选择归一化参数$\lambda$过大的话，则会把所有参数的作用都减小，可能造成欠拟合。</p>
<h3 id="Regularized-Linear-Regression"><a href="#Regularized-Linear-Regression" class="headerlink" title="Regularized Linear Regression"></a>Regularized Linear Regression</h3><p>归一化的线性回归代价函数为：</p>
<p>$$<br>J(\theta)=\frac{1}{2m}\big[ \sum_{i=1}^{m}((h_{\theta}(x^{(i)})-y^{(i)})^{2}+\lambda\sum_{j=1}^{m}\theta_{j}^{2}) \big]<br>$$</p>
<p>如果我们采用梯度下降来实现这个代价函数的最小化，因为我们没有对$\theta_0$进行归一化，所以梯度下降算法将分为两种情形：</p>
<p>$$<br>\quad \theta_0=\theta_0-\alpha\frac{1}{m}\sum_{i=1}^{m}\big[ h_{\theta}(x^{(i)})-y^{(i)} \big]x_{0}^{(i)} \<br>\quad \theta_{j}=\theta_{j}-\alpha\bigg[ \big[\frac{1}{m}\sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})x_{j}^{(i)} \big]+\frac{\lambda}{m}\theta_{j} \bigg]  \<br>j \in [1 \dots n]<br>$$</p>
<p>对上式变化可得：</p>
<p>$$<br>\theta_j=\theta_{j}(1-\alpha\frac{\lambda}{m})-\alpha\frac{1}{m}\sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})x_j^{(i)}<br>$$</p>
<p>我们可以看到，归一化方程的梯度下降算法就是在每次迭代过程中，令$\theta$减少一个额外的值。</p>
<h2 id="Normal-Equation"><a href="#Normal-Equation" class="headerlink" title="Normal Equation"></a>Normal Equation</h2><p>我们也可以使用正规方程来求解归一化线性回归模型：</p>
<p>$$<br>\theta = ( X^{T}X - {\lambda}L )^{-1}X^{T}y<br>$$</p>
<p>其中：</p>
<p>$$<br>L =<br>\begin{bmatrix}<br>0 \<br>\quad &amp; 1 \<br>\quad &amp; \quad &amp; \ddots \<br>\quad &amp; \quad &amp; \quad &amp; 1 \<br>\end{bmatrix}_{(m+1) \times (n+1)}<br>$$</p>
<p>注意：如果$X^{T}X$不可逆，则$X^{T}X+{\lambda}L$也不可逆。</p>
<h1 id="错题集锦"><a href="#错题集锦" class="headerlink" title="错题集锦"></a>错题集锦</h1><p>下面是我在完成<a href="https://www.coursera.org/learn/machine-learning/home" target="_blank" rel="noopener">课程</a>的小测验过程中的错题，我将相关知识点罗列如下：</p>
<ol>
<li>在模型中添加新的属性仅仅可以提高在训练集上的匹配程度。</li>
<li>在$m \geq 1 $个样本上训练得到的 Logistic Regression 代价函数一定大于等于1.</li>
<li>Logistic Regression 的代价函数是“凸函数”，所以梯度下降算法一定会达到全局最优点。但是我们依然可能选择使用优化算法，因为这些算法可以更加高效地习得模型的最佳参数，并且不需要我们选择 Learning Rate。</li>
<li>通过添加新的属性，我们的模型一定会更加精确地表达样本的特点，从而可以习得更加复杂的假设来匹配训练样本。</li>
<li>当$\lambda$被设为1时，我们使用归一化来减少$\theta$的值。这样，$\theta$会更小。</li>
<li>归一化通过“惩罚”参数的作用，可能会实现一个更简单的模型，会分类错误更多的样本。</li>
<li>如果算法在一个训练样本上的分类效果很差的话，这意味着模型处于欠拟合状态。这种情况下，以应该通过增加属性数量、使用多项式回归等方法来提高模型的性能。</li>
</ol>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ol>
<li><a href="https://www.amazon.cn/%E5%9B%BE%E4%B9%A6/dp/B01ARKEV1G" target="_blank" rel="noopener">机器学习</a> 周志华</li>
<li><a href="https://www.coursera.org/learn/machine-learning/home" target="_blank" rel="noopener">Machine Learning</a> Stanford</li>
</ol>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/MOOC/" rel="tag"># MOOC</a>
              <a href="/tags/Machine-Learning/" rel="tag"># Machine Learning</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2016/12/22/Linear-Regression/" rel="prev" title="【机器学习课程笔记】| 线性回归（Linear Regression）">
      <i class="fa fa-chevron-left"></i> 【机器学习课程笔记】| 线性回归（Linear Regression）
    </a></div>
      <div class="post-nav-item">
    <a href="/2017/01/10/Neural-Networks/" rel="next" title="【机器学习课程笔记】| Neural Networks">
      【机器学习课程笔记】| Neural Networks <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    
  <div class="comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#分类问题"><span class="nav-number">1.</span> <span class="nav-text">分类问题</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#利用线性回归解决分类问题"><span class="nav-number">1.1.</span> <span class="nav-text">利用线性回归解决分类问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Sigmoid-函数"><span class="nav-number">1.2.</span> <span class="nav-text">Sigmoid 函数</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Cost-Function"><span class="nav-number">2.</span> <span class="nav-text">Cost Function</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#优化"><span class="nav-number">2.1.</span> <span class="nav-text">优化</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#多分类问题"><span class="nav-number">3.</span> <span class="nav-text">多分类问题</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#One-vs-All"><span class="nav-number">3.1.</span> <span class="nav-text">One-vs-All</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#过度拟合问题（Overfitting）"><span class="nav-number">3.2.</span> <span class="nav-text">过度拟合问题（Overfitting）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Regularization"><span class="nav-number">3.3.</span> <span class="nav-text">Regularization</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Regularization-Cost-Funtion"><span class="nav-number">3.3.1.</span> <span class="nav-text">Regularization - Cost Funtion</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Regularized-Linear-Regression"><span class="nav-number">3.3.2.</span> <span class="nav-text">Regularized Linear Regression</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Normal-Equation"><span class="nav-number">3.4.</span> <span class="nav-text">Normal Equation</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#错题集锦"><span class="nav-number">4.</span> <span class="nav-text">错题集锦</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#参考文献"><span class="nav-number">5.</span> <span class="nav-text">参考文献</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Chuanlei Guo</p>
  <div class="site-description" itemprop="description">正因为未知，人与人之间的羁绊才愈发迷人</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">25</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">26</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/ChuanleiGuo" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;ChuanleiGuo" rel="noopener" target="_blank"><i class="github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:chuanleiguo@gmail.com" title="E-Mail → mailto:chuanleiguo@gmail.com" rel="noopener" target="_blank"><i class="envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="http://weibo.com/bestchuan" title="Weibo → http:&#x2F;&#x2F;weibo.com&#x2F;bestchuan" rel="noopener" target="_blank"><i class="weibo fa-fw"></i>Weibo</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2016 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chuanlei Guo</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://chuanleiguo-com.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  var disqus_config = function() {
    this.page.url = "http://chuanleiguo.com/2017/01/01/Logistic-Regression/";
    this.page.identifier = "2017/01/01/Logistic-Regression/";
    this.page.title = "【机器学习课程笔记】| Logistic Regression";
    };
  NexT.utils.loadComments(document.querySelector('#disqus_thread'), () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://chuanleiguo-com.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });
</script>

</body>
</html>
